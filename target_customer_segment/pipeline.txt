2. Предположительные методы подготовки данных
 
 1. Изучение данных behavior_2023  и feedback для понимания структуры и типов данных: методы head(), info().
 2. Поиск и обработка пропущенных значений: метод snull(), удаление или замена на медианные значения.
 3. Поиск и удаление дубликатов: метод duplicated().
 4. Поиск и обработка выбросов метод describe().
 5. Проверка данные на согласованность.
 6. Создание категориальных переменных на основе существующих данных.
 7. Обработка дат, добавление дополнительных полей с месяцами или кварталами для работы с сезонностью.
 8. Генерация новых признаков на основе существующих данных.
 9. Преобразование категориальных признаков в числовые.
 10. Поиск корреляции в данных: тепловые карты, матрица корреляции, попарные графики корреляций pairplot()
 11. Отбор признаков для обучения модели Присутствие в данных неинформативных признаков приводит к снижению точности многих моделей.
 12. Определение количества кластеров: предварительно 3 кластера.



4. План по валидации качества модели

Для оценки эффективности работы алгоритма кластеризации и выбора 
наилучшего метода решения задачи кластеризации пользователей планируется протестировать следующие метрики:
1. Accuracy
-  Описывает общую точность предсказания модели по всем классам (TP+TN)/(TP+TN+FP+FN).
-  Подойдет только в случае сбалансированных классов.
 
2. Precision
- Precision = TP/(TP+FP).
-  Показывает долю объектов, названных моделью положительными и при этом действительно являющимися положительными.
-  Не зависит от соотношения классов, применимы в условиях несбалансированных выборок.
 
3. Recall
-  Recall = TP / (TP + FN).
-  Показывает какую долю объектов положительного класса из всех объектов положительного класса, которые нашел алгоритм.
-  Не зависит от соотношения классов, применимы в условиях несбалансированных выборок.
 
4. F1
-  F1 = 2 * (Precision * Recall) / (Precision + Recall)
-  Показывает одновременно насколько хорошо модель находит объекты положительного класса из всех объектов положительного класса и какая доля из тех, кого алгоритм назвал положительным классом, действительно являются положительным классом.
 
В случае бинарного классификатора эффективно использовать такие метрики оценки эффективности моделей, как ROC и AUC
5. ROC
-  График, который иллюстрирует производительность классификационной модели при всех возможных порогах классификации. Ось X данного графика представляет собой FPR (ложноположительную частоту, а ось Y — TRP (истинноположительную частоту)
-  TRP = TP/(TP+FN), FPR = FP / (TN + FP)
6. AUC
-  Позволяет суммировать производительность модели одним числом, измеряя площадь под кривой ROC. AUC колеблется от 0 до 1, где более высокое значение AUC указывает на более высокую производительность модели.
 
Предварительно планируется ориентироваться на F1 при выборе оптимальной модели.
